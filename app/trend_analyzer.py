
"""
trend_analyzer.py - –ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–µ–≥–æ–≤ –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π
"""
import json
from datetime import datetime, timedelta
from collections import defaultdict, Counter
from typing import Dict, List, Any, Tuple
from database import get_db_connection
from classifier import LLMMetadataClassifier
import os

class TrendAnalyzer:
    def __init__(self):
        self.conn = get_db_connection()
    
    def analyze_tag_trends(self, days_back: int = 30) -> Dict[str, Any]:
        """–ê–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤ –ø–æ —Ç–µ–≥–∞–º –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ N –¥–Ω–µ–π"""
        
        try:
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞—Ç—É –Ω–∞—á–∞–ª–∞ –ø–µ—Ä–∏–æ–¥–∞
            start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')
            
            # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ –Ω–æ–≤–æ—Å—Ç–∏ –∑–∞ –ø–µ—Ä–∏–æ–¥
            cursor = self.conn.execute('''
                SELECT id, text, metadata, llm_tags, sentiment, created_at
                FROM chunks
                WHERE date(created_at) >= date(?)
                ORDER BY created_at
            ''', (start_date,))
            
            news_items = cursor.fetchall()
            
            # –°—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
            tag_stats = defaultdict(lambda: {
                'total': 0,
                'positive': 0,
                'negative': 0,
                'neutral': 0,
                'by_day': defaultdict(lambda: {'total': 0, 'positive': 0, 'negative': 0, 'neutral': 0}),
                'first_seen': None,
                'last_seen': None
            })
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –∫–∞–∂–¥—É—é –Ω–æ–≤–æ—Å—Ç—å
            for item in news_items:
                try:
                    date_str = item['created_at'][:10]  # YYYY-MM-DD
                    sentiment = item['sentiment']
                    
                    # –ü–∞—Ä—Å–∏–º —Ç–µ–≥–∏
                    tags = []
                    if item['llm_tags']:
                        try:
                            tags = json.loads(item['llm_tags'])
                        except:
                            pass
                    
                    for tag in tags:
                        tag = tag.strip()
                        if not tag:
                            continue
                            
                        stats = tag_stats[tag]
                        stats['total'] += 1
                        
                        if sentiment == 'positive':
                            stats['positive'] += 1
                            stats['by_day'][date_str]['positive'] += 1
                        elif sentiment == 'negative':
                            stats['negative'] += 1
                            stats['by_day'][date_str]['negative'] += 1
                        elif sentiment == 'neutral':
                            stats['neutral'] += 1
                            stats['by_day'][date_str]['neutral'] += 1
                        
                        stats['by_day'][date_str]['total'] += 1
                        
                        # –û–±–Ω–æ–≤–ª—è–µ–º –¥–∞—Ç—ã
                        if not stats['first_seen'] or date_str < stats['first_seen']:
                            stats['first_seen'] = date_str
                        if not stats['last_seen'] or date_str > stats['last_seen']:
                            stats['last_seen'] = date_str
                            
                except Exception as e:
                    print(f"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –Ω–æ–≤–æ—Å—Ç–∏ {item['id']}: {e}")
                    continue
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–∞–∂–¥—ã–π —Ç–µ–≥
            signals = []
            
            for tag, stats in tag_stats.items():
                if stats['total'] < 3:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
                    continue
                
                # –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
                total = stats['total']
                positive_pct = (stats['positive'] / total * 100) if total > 0 else 0
                negative_pct = (stats['negative'] / total * 100) if total > 0 else 0
                neutral_pct = (stats['neutral'] / total * 100) if total > 0 else 0
                
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –¥–Ω—è–º –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç—Ä–µ–Ω–¥–∞
                days_data = list(stats['by_day'].items())
                days_data.sort()  # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ –¥–∞—Ç–µ
                
                if len(days_data) < 3:  # –ù—É–∂–Ω–æ –º–∏–Ω–∏–º—É–º 3 –¥–Ω—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–∞
                    trend = 'stable'
                else:
                    # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ 7 –¥–Ω–µ–π
                    recent_days = days_data[-7:]
                    if len(recent_days) >= 3:
                        # –°—á–∏—Ç–∞–µ–º —Å—Ä–µ–¥–Ω–µ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–æ–≤–æ—Å—Ç–µ–π –≤ –ø–µ—Ä–≤–æ–π –∏ –≤—Ç–æ—Ä–æ–π –ø–æ–ª–æ–≤–∏–Ω–µ –ø–µ—Ä–∏–æ–¥–∞
                        mid = len(recent_days) // 2
                        # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –±–µ—Ä–µ–º –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (stats_dict)
                        first_half = sum(d[1]['total'] for d in recent_days[:mid])
                        second_half = sum(d[1]['total'] for d in recent_days[mid:])

                        if second_half > first_half * 1.5:  # –†–æ—Å—Ç –±–æ–ª–µ–µ 50%
                            trend = 'up'
                        elif second_half < first_half * 0.7:  # –ü–∞–¥–µ–Ω–∏–µ –±–æ–ª–µ–µ 30%
                            trend = 'down'
                        else:
                            trend = 'stable'
                    else:
                        trend = 'stable'
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø —Å–∏–≥–Ω–∞–ª–∞
                signal_type = self._determine_signal_type(
                    positive_pct, negative_pct, total, trend, days_data
                )
                
                if signal_type:
                    signal = self._create_signal(
                        tag, signal_type, stats, 
                        positive_pct, negative_pct, 
                        total, trend, days_data
                    )
                    if signal:
                        signals.append(signal)
            
            # –°–æ—Ä—Ç–∏—Ä—É–µ–º —Å–∏–≥–Ω–∞–ª—ã –ø–æ –≤–∞–∂–Ω–æ—Å—Ç–∏
            signals.sort(key=lambda x: x.get('priority', 0), reverse=True)
            
            return {
                'signals': signals[:10],  # –¢–æ–ø 10 —Å–∏–≥–Ω–∞–ª–æ–≤
                'total_tags_analyzed': len(tag_stats),
                'period_days': days_back,
                'analysis_date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            }
            
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Ç—Ä–µ–Ω–¥–æ–≤: {e}")
            import traceback
            traceback.print_exc()
            return {
                'signals': [],
                'error': str(e)
            }
        finally:
            self.conn.close()
    
    # trend_analyzer.py - –∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è
    def _determine_signal_type(self, positive_pct: float, negative_pct: float, 
                               total: int, trend: str, days_data: List[Tuple[str, Dict]]) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∞–Ω–∞–ª–∏–∑–∞"""

        if total < 5:  # –ú–∞–ª–æ –¥–∞–Ω–Ω—ã—Ö
            return None

        # –ö—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
        if negative_pct > 60 and total >= 10:
            if trend == 'up':
                return 'growing_problem'  # –ù–∞—Ä–∞—Å—Ç–∞—é—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞
            else:
                return 'problem'  # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –ø—Ä–æ–±–ª–µ–º–∞

        if positive_pct > 60 and total >= 8:
            if trend == 'up':
                return 'growing_opportunity'  # –†–∞—Å—Ç—É—â–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å
            else:
                return 'opportunity'  # –°—Ç–∞–±–∏–ª—å–Ω–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å

        # –ù–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ (—Ç–µ–≥ –ø–æ—è–≤–∏–ª—Å—è –Ω–µ–¥–∞–≤–Ω–æ –∏ –±—ã—Å—Ç—Ä–æ –Ω–∞–±–∏—Ä–∞–µ—Ç)
        if len(days_data) > 0:
            first_date_str = days_data[0][0]
            last_date_str = days_data[-1][0]
            try:
                first_date = datetime.strptime(first_date_str, '%Y-%m-%d')
                last_date = datetime.strptime(last_date_str, '%Y-%m-%d')
                days_active = (last_date - first_date).days + 1

                if days_active <= 7 and total >= 5:  # –ü–æ—è–≤–∏–ª—Å—è –∑–∞ –Ω–µ–¥–µ–ª—é –∏ —É–∂–µ 5+ —É–ø–æ–º–∏–Ω–∞–Ω–∏–π
                    if positive_pct > 50:
                        return 'new_opportunity'  # –ù–æ–≤–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å
                    elif negative_pct > 50:
                        return 'new_problem'  # –ù–æ–≤–∞—è –ø—Ä–æ–±–ª–µ–º–∞
                    else:
                        return 'new_trend'  # –ù–æ–≤—ã–π –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π —Ç—Ä–µ–Ω–¥
            except:
                pass
            
        # –†–µ–∑–∫–∏–π —Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ
        if len(days_data) >= 7:
            recent = days_data[-7:]
            if len(recent) >= 4:
                # –ë–µ—Ä–µ–º –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞ (stats_dict)
                recent_counts = [d[1]['total'] for d in recent]
                if len(recent_counts) >= 2:
                    avg_first = sum(recent_counts[:len(recent_counts)//2]) / (len(recent_counts)//2)
                    avg_second = sum(recent_counts[len(recent_counts)//2:]) / (len(recent_counts)//2)

                    if avg_second > avg_first * 2:  # –†–æ—Å—Ç –≤ 2 —Ä–∞–∑–∞
                        if positive_pct > 40:
                            return 'growing_opportunity'
                        elif negative_pct > 40:
                            return 'growing_problem'
                        else:
                            return 'emerging_trend'

        return None
        
        # –†–µ–∑–∫–∏–π —Ä–æ—Å—Ç/–ø–∞–¥–µ–Ω–∏–µ
        if len(days_data) >= 7:
            recent = days_data[-7:]
            if len(recent) >= 4:
                # –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï: –±–µ—Ä–µ–º –≤—Ç–æ—Ä–æ–π —ç–ª–µ–º–µ–Ω—Ç –∫–æ—Ä—Ç–µ–∂–∞
                recent_counts = [d[1]['total'] for d in recent]
                avg_first = sum(recent_counts[:len(recent_counts)//2]) / (len(recent_counts)//2)
                avg_second = sum(recent_counts[len(recent_counts)//2:]) / (len(recent_counts)//2)

                if avg_second > avg_first * 2:  # –†–æ—Å—Ç –≤ 2 —Ä–∞–∑–∞
                    if positive_pct > 40:
                        return 'growing_opportunity'
                    elif negative_pct > 40:
                        return 'growing_problem'
                    else:
                        return 'emerging_trend'
        
        return None
    
    def _create_signal(self, tag: str, signal_type: str, stats: Dict, 
                      positive_pct: float, negative_pct: float, 
                      total: int, trend: str, days_data: List[Tuple[str, Dict]]) -> Dict[str, Any]:
    
        """–°–æ–∑–¥–∞–Ω–∏–µ –æ–±—ä–µ–∫—Ç–∞ —Å–∏–≥–Ω–∞–ª–∞"""
        
        # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º –¥–∞—Ç—ã
        first_seen = stats.get('first_seen', '')
        last_seen = stats.get('last_seen', '')
        
        if first_seen:
            try:
                # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º YYYY-MM-DD –≤ DD.MM.YYYY
                date_obj = datetime.strptime(first_seen, '%Y-%m-%d')
                first_seen_formatted = date_obj.strftime('%d.%m.%Y')
            except:
                first_seen_formatted = first_seen
        else:
            first_seen_formatted = '–Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–æ'
            
        if last_seen:
            try:
                date_obj = datetime.strptime(last_seen, '%Y-%m-%d')
                last_seen_formatted = date_obj.strftime('%d.%m.%Y')
            except:
                last_seen_formatted = last_seen
        else:
            last_seen_formatted = '–Ω–µ–¥–∞–≤–Ω–æ'
        
        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        signal = {
            'tag': tag,
            'type': signal_type,
            'mentions': total,
            'trend': trend,
            'sentiment_distribution': {
                'positive': round(positive_pct, 1),
                'negative': round(negative_pct, 1),
                'neutral': round(100 - positive_pct - negative_pct, 1)
            },
            'first_seen': first_seen_formatted,  # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–∞—Ç–∞
            'last_seen': last_seen_formatted     # –§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –¥–∞—Ç–∞
        }

        # –ë–∞–∑–æ–≤–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
        signal = {
            'tag': tag,
            'type': signal_type,
            'mentions': total,
            'trend': trend,
            'sentiment_distribution': {
                'positive': round(positive_pct, 1),
                'negative': round(negative_pct, 1),
                'neutral': round(100 - positive_pct - negative_pct, 1)
            },
            'first_seen': stats['first_seen'],
            'last_seen': stats['last_seen']
        }
        
        # –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞
        type_config = {
            'problem': {
                'title': f'–ü—Ä–æ–±–ª–µ–º–∞: {tag}',
                'description': f'–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π ({negative_pct:.1f}%). –¢—Ä–µ–±—É–µ—Ç –≤–Ω–∏–º–∞–Ω–∏—è.',
                'icon': 'fas fa-exclamation-triangle',
                'priority': 80,
                'color': 'danger'
            },
            'growing_problem': {
                'title': f'–ù–∞—Ä–∞—Å—Ç–∞—é—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞: {tag}',
                'description': f'–ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è —Ä–∞—Å—Ç—É—Ç ({negative_pct:.1f}%). –ù–µ–æ–±—Ö–æ–¥–∏–º–æ —Å—Ä–æ—á–Ω–æ–µ –≤–º–µ—à–∞—Ç–µ–ª—å—Å—Ç–≤–æ.',
                'icon': 'fas fa-fire',
                'priority': 95,
                'color': 'danger'
            },
            'opportunity': {
                'title': f'–í–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å: {tag}',
                'description': f'–í—ã—Å–æ–∫–∏–π —É—Ä–æ–≤–µ–Ω—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π ({positive_pct:.1f}%). –ü–æ—Ç–µ–Ω—Ü–∏–∞–ª –¥–ª—è —Ä–∞–∑–≤–∏—Ç–∏—è.',
                'icon': 'fas fa-lightbulb',
                'priority': 70,
                'color': 'success'
            },
            'growing_opportunity': {
                'title': f'–†–∞—Å—Ç—É—â–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å: {tag}',
                'description': f'–ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è –±—ã—Å—Ç—Ä–æ —Ä–∞—Å—Ç—É—Ç ({positive_pct:.1f}%). –û—Ç–ª–∏—á–Ω—ã–π –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª.',
                'icon': 'fas fa-rocket',
                'priority': 85,
                'color': 'success'
            },
            'new_opportunity': {
                'title': f'–ù–æ–≤–∞—è –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å: {tag}',
                'description': f'–ù–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ —Å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ–º. {total} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∑–∞ –Ω–µ–¥–µ–ª—é.',
                'icon': 'fas fa-star',
                'priority': 90,
                'color': 'success'
            },
            'new_problem': {
                'title': f'–ù–æ–≤–∞—è –ø—Ä–æ–±–ª–µ–º–∞: {tag}',
                'description': f'–ù–æ–≤—ã–π —Ç—Ä–µ–Ω–¥ —Å –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–º –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ–º. {total} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∑–∞ –Ω–µ–¥–µ–ª—é.',
                'icon': 'fas fa-bolt',
                'priority': 88,
                'color': 'danger'
            },
            'new_trend': {
                'title': f'–ù–æ–≤—ã–π —Ç—Ä–µ–Ω–¥: {tag}',
                'description': f'–ù–æ–≤–∞—è —Ç–µ–º–∞ —Å {total} —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º–∏ –∑–∞ –Ω–µ–¥–µ–ª—é. –¢—Ä–µ–±—É–µ—Ç –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.',
                'icon': 'fas fa-eye',
                'priority': 60,
                'color': 'warning'
            },
            'emerging_trend': {
                'title': f'–ó–∞—Ä–æ–∂–¥–∞—é—â–∏–π—Å—è —Ç—Ä–µ–Ω–¥: {tag}',
                'description': f'–ë—ã—Å—Ç—Ä—ã–π —Ä–æ—Å—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π ({trend} —Ç—Ä–µ–Ω–¥). {total} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –≤—Å–µ–≥–æ.',
                'icon': 'fas fa-seedling',
                'priority': 75,
                'color': 'info'
            }
        }
        
        config = type_config.get(signal_type, {
            'title': f'–¢—Ä–µ–Ω–¥: {tag}',
            'description': f'–ê–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–µ–≥—É: {total} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π.',
            'icon': 'fas fa-chart-line',
            'priority': 50,
            'color': 'info'
        })
        
        signal.update(config)
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        signal['recommendations'] = self._generate_recommendations(signal_type, tag, positive_pct, negative_pct)
        
        return signal
    
    def _generate_recommendations(self, signal_type: str, tag: str, 
                                 positive_pct: float, negative_pct: float) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ç–∏–ø–∞ —Å–∏–≥–Ω–∞–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º LLM"""

        # –°–æ–∑–¥–∞–µ–º —ç–∫–∑–µ–º–ø–ª—è—Ä –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä–∞ –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è LLM
        try:
            from classifier import LLMMetadataClassifier
            classifier = LLMMetadataClassifier(api_key=os.getenv("GROQ_API_KEY"))

            sentiment_distribution = {
                'positive': round(positive_pct, 1),
                'negative': round(negative_pct, 1),
                'neutral': round(100 - positive_pct - negative_pct, 1)
            }

            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç—Ä–µ–Ω–¥ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–æ—Ü–µ–Ω—Ç–æ–≤
            if positive_pct > negative_pct:
                trend = 'up' if positive_pct > 55 else 'stable'
            else:
                trend = 'down' if negative_pct > 55 else 'stable'

            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç LLM
            recommendations = classifier.generate_recommendations(
                tag=tag,
                signal_type=signal_type,
                sentiment_distribution=sentiment_distribution,
                mentions_count=0,  # –ë—É–¥–µ—Ç —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ –ø–æ–∑–∂–µ
                trend=trend
            )

            if recommendations and len(recommendations) >= 2:
                print(f"ü§ñ LLM —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª {len(recommendations)} —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π –¥–ª—è '{tag}'")
                return recommendations[:3]  # –ë–µ—Ä–µ–º —Ç–æ–ø-3 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π —á–µ—Ä–µ–∑ LLM: {e}")

        # –†–µ–∑–µ—Ä–≤–Ω—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –µ—Å–ª–∏ LLM –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª
        recommendations = []

        if 'problem' in signal_type:
            if negative_pct > 70:
                recommendations.append(f'–°—Ä–æ—á–Ω–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ø—Ä–∏—á–∏–Ω—ã –Ω–µ–≥–∞—Ç–∏–≤–∞ –ø–æ —Ç–µ–º–µ "{tag}"')
                recommendations.append('–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å –ø–ª–∞–Ω –∫–æ–º–º—É–Ω–∏–∫–∞—Ü–∏–∏ –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–µ–≥–∞—Ç–∏–≤–∞')
            else:
                recommendations.append(f'–ú–æ–Ω–∏—Ç–æ—Ä–∏—Ç—å —Å–∏—Ç—É–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ "{tag}"')
                recommendations.append('–ü—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –Ω–µ–≥–∞—Ç–∏–≤–Ω—ã—Ö —É–ø–æ–º–∏–Ω–∞–Ω–∏–π')

        elif 'opportunity' in signal_type:
            if positive_pct > 70:
                recommendations.append(f'–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥ –ø–æ —Ç–µ–º–µ "{tag}" –≤ –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–µ')
                recommendations.append('–†–∞—Å—Å–º–æ—Ç—Ä–µ—Ç—å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ –¥–∞–Ω–Ω–æ–µ –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ')
            else:
                recommendations.append(f'–£—Å–∏–ª–∏—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–µ–º–µ "{tag}"')
                recommendations.append('–ò–∑—É—á–∏—Ç—å —É—Å–ø–µ—à–Ω—ã–µ –∫–µ–π—Å—ã –ø–æ –¥–∞–Ω–Ω–æ–π —Ç–µ–º–µ')

        elif 'new' in signal_type or 'emerging' in signal_type:
            recommendations.append(f'–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ä–µ–≥—É–ª—è—Ä–Ω—ã–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Ç–µ–º—ã "{tag}"')
            recommendations.append('–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å —Ä–∞–Ω–Ω–∏–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ç—Ä–µ–Ω–¥–∞')
            recommendations.append('–†–∞–∑—Ä–∞–±–æ—Ç–∞—Ç—å —Å—Ç—Ä–∞—Ç–µ–≥–∏—é —Ä–µ–∞–≥–∏—Ä–æ–≤–∞–Ω–∏—è')

        # –û–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        if not recommendations:
            recommendations.append(f'–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å –ø–æ —Ç–µ–º–µ "{tag}"')

        recommendations.append('–û–±–Ω–æ–≤–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ 3 –¥–Ω—è –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –¥–∏–Ω–∞–º–∏–∫–∏')

        return recommendations[:4]  # –ú–∞–∫—Å–∏–º—É–º 4 —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏


def get_trend_signals() -> List[Dict[str, Any]]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–∫—Ç–∏–≤–Ω—ã—Ö —Å–∏–≥–Ω–∞–ª–æ–≤ –¥–ª—è –¥–∞—à–±–æ—Ä–¥–∞"""
    analyzer = TrendAnalyzer()
    result = analyzer.analyze_tag_trends(days_back=30)
    
    if 'signals' in result and result['signals']:
        return result['signals'][:6]  # –ë–µ—Ä–µ–º —Ç–æ–ø-6 —Å–∏–≥–Ω–∞–ª–æ–≤
    
    return []