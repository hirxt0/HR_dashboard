from typing import List, Dict
import json
from tqdm import tqdm

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –Ω–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
try:
    from metadata_processor import MetadataProcessorRU
    METADATA_PROCESSOR_AVAILABLE = True
except ImportError:
    METADATA_PROCESSOR_AVAILABLE = False
    print("‚ö†Ô∏è MetadataProcessorRU –Ω–µ –Ω–∞–π–¥–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä")


class Classifier:
    """
    –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä —á–∞–Ω–∫–æ–≤ —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
    """
    
    def __init__(self, cfg, llm=None):
        self.cfg = cfg
        self.llm = llm
        self.mode = cfg["llm"].get("mode", "mock")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º MetadataProcessorRU –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–µ–Ω
        self.metadata_processor = None
        if METADATA_PROCESSOR_AVAILABLE:
            try:
                print(" –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è MetadataProcessorRU...")
                self.metadata_processor = MetadataProcessorRU()
                print(" MetadataProcessorRU –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!")
            except Exception as e:
                print(f" –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ MetadataProcessorRU: {e}")
                print("–ü–µ—Ä–µ–∫–ª—é—á–∞—é—Å—å –Ω–∞ –±–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ç–æ—Ä")

    def classify_chunks(self, chunks: List[Dict]) -> List[Dict]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä—É–µ—Ç —Å–ø–∏—Å–æ–∫ —á–∞–Ω–∫–æ–≤, –¥–æ–±–∞–≤–ª—è—è –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        """
        print("–ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–Ø –ß–ê–ù–ö–û–í")
        print(f"–†–µ–∂–∏–º: {'MetadataProcessorRU' if self.metadata_processor else 'Mock'}")
        print(f"–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —á–∞–Ω–∫–æ–≤: {len(chunks)}")
        print(f"{'='*60}\n")
        
        if self.metadata_processor:
            return self._classify_with_metadata_processor(chunks)
        else:
            return self._classify_mock(chunks)

    def _classify_with_metadata_processor(self, chunks: List[Dict]) -> List[Dict]:
        """
        –ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º MetadataProcessorRU
        """
        batch_size = 50
        results = []
        
        for i in tqdm(range(0, len(chunks), batch_size), desc="–ö–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"):
            batch = chunks[i:i + batch_size]
            
            for chunk in batch:
                try:
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —á–∞–Ω–∫ —á–µ—Ä–µ–∑ MetadataProcessorRU
                    result = self.metadata_processor.process_chunk(
                        chunk_id=chunk.get('chunk_id', f'chunk_{i}'),
                        text=chunk['text']
                    )
                    
                    # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –∫ —á–∞–Ω–∫—É
                    chunk['meta'] = {
                        'tags': result['metadata']['tags'],
                        'sentiment': result['metadata']['sentiment'],
                        'sentiment_score': result['metadata']['sentiment_score'],
                        'category': result['metadata']['topic'],
                        'topic_scores': result['metadata']['topic_scores'],
                        'topic_details': result['metadata']['topic_details'],
                        'is_insider': result['metadata']['is_insider'],
                        'insider_confidence': result['metadata']['insider_confidence']
                    }
                    
                    results.append(chunk)
                    
                except Exception as e:
                    print(f" –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —á–∞–Ω–∫–∞ {chunk.get('chunk_id')}: {e}")
                    # –î–æ–±–∞–≤–ª—è–µ–º —á–∞–Ω–∫ –±–µ–∑ –º–µ—Ç–∞–¥–∞–Ω–Ω—ã—Ö
                    chunk['meta'] = self._get_fallback_meta()
                    results.append(chunk)
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        self._print_classification_stats(results)
        
        return results

    def _classify_mock(self, chunks: List[Dict]) -> List[Dict]:
        """
        Mock-–∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)
        """
        import random
        
        categories = ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–±–∏–∑–Ω–µ—Å", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–Ω–∞—É–∫–∞", "–æ–±—â–µ–µ"]
        sentiments = ["positive", "neutral", "negative"]
        
        for chunk in tqdm(chunks, desc="Mock –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è"):
            chunk['meta'] = {
                'category': random.choice(categories),
                'tags': [f"tag_{i}" for i in range(3)],
                'sentiment': random.choice(sentiments),
                'sentiment_score': random.random(),
                'is_insider': False,
                'insider_confidence': 0.0
            }
        
        return chunks

    def _get_fallback_meta(self) -> Dict:
        """
        –ú–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø—Ä–∏ –æ—à–∏–±–∫–µ
        """
        return {
            'category': '–æ–±—â–µ–µ',
            'tags': [],
            'sentiment': 'neutral',
            'sentiment_score': 0.0,
            'is_insider': False,
            'insider_confidence': 0.0
        }

    def _print_classification_stats(self, chunks: List[Dict]):
        """
        –í—ã–≤–æ–¥–∏—Ç —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        from collections import Counter
        
        print("–°–¢–ê–¢–ò–°–¢–ò–ö–ê –ö–õ–ê–°–°–ò–§–ò–ö–ê–¶–ò–ò")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º
        categories = [c['meta'].get('category', 'unknown') for c in chunks]
        cat_counts = Counter(categories)
        
        print("\n –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º:")
        for cat, count in cat_counts.most_common():
            percentage = (count / len(chunks)) * 100
            print(f"  ‚Ä¢ {cat:20s}: {count:3d} ({percentage:5.1f}%)")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏
        sentiments = [c['meta'].get('sentiment', 'unknown') for c in chunks]
        sent_counts = Counter(sentiments)
        
        print("\n –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø–æ —Ç–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏:")
        for sent, count in sent_counts.most_common():
            percentage = (count / len(chunks)) * 100
            print(f"  ‚Ä¢ {sent:20s}: {count:3d} ({percentage:5.1f}%)")
        
        # –ò–Ω—Å–∞–π–¥–µ—Ä—ã
        insiders = [c for c in chunks if c['meta'].get('is_insider', False)]
        if insiders:
            print(f"\n –ò–Ω—Å–∞–π–¥–µ—Ä—Å–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è: {len(insiders)} —á–∞–Ω–∫–æ–≤")
            avg_confidence = sum(c['meta'].get('insider_confidence', 0) for c in insiders) / len(insiders)
            print(f"  –°—Ä–µ–¥–Ω—è—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {avg_confidence:.2%}")
        
        # –°–∞–º—ã–µ —á–∞—Å—Ç—ã–µ —Ç–µ–≥–∏
        all_tags = []
        for c in chunks:
            all_tags.extend(c['meta'].get('tags', []))
        
        if all_tags:
            tag_counts = Counter(all_tags)
            print("\n –¢–æ–ø-10 —Ç–µ–≥–æ–≤:")
            for tag, count in tag_counts.most_common(10):
                print(f"  ‚Ä¢ {tag:20s}: {count}")
        
        print(f"\n{'='*60}\n")

    def save_classification_report(self, chunks: List[Dict], output_path: str):
        """
        –°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—ã–π –æ—Ç—á—ë—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏
        """
        from collections import Counter
        
        report = {
            'total_chunks': len(chunks),
            'categories': dict(Counter(c['meta'].get('category', 'unknown') for c in chunks)),
            'sentiments': dict(Counter(c['meta'].get('sentiment', 'unknown') for c in chunks)),
            'insider_count': len([c for c in chunks if c['meta'].get('is_insider', False)]),
            'top_tags': dict(Counter([tag for c in chunks for tag in c['meta'].get('tags', [])]).most_common(20))
        }
        
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        
        print(f"üìÑ –û—Ç—á—ë—Ç –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {output_path}")


# –î–ª—è –æ–±—Ä–∞—Ç–Ω–æ–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ —Å–æ —Å—Ç–∞—Ä—ã–º –∫–æ–¥–æ–º
def classify_chunk_mock(chunk_text: str) -> Dict:
    """–£—Å—Ç–∞—Ä–µ–≤—à–∞—è —Ñ—É–Ω–∫—Ü–∏—è, –æ—Å—Ç–∞–≤–ª–µ–Ω–∞ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
    import random
    categories = ["—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–±–∏–∑–Ω–µ—Å", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–Ω–∞—É–∫–∞", "–æ–±—â–µ–µ"]
    return {
        'category': random.choice(categories),
        'tags': [f"tag_{i}" for i in range(3)],
        'sentiment': random.choice(["positive", "neutral", "negative"])
    }