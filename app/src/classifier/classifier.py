# classifier.py
import sqlite3
import json
from typing import List, Dict, Optional, Tuple
import requests
from dataclasses import dataclass
import time
import re
from dotenv import load_dotenv
import os

load_dotenv()
API_KEY = os.getenv("GROQ_API_KEY")

@dataclass
class ChunkData:
    """–°—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–Ω—ã—Ö —á–∞–Ω–∫–∞"""
    chunk_id: int
    text: str
    existing_metadata: Dict

class LLMMetadataClassifier:
    """
    LLM –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç —Ç–µ–≥–∏ –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞ —Å –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º
    """
    
    # –°–ø–∏—Å–æ–∫ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö —Ç–µ–≥–æ–≤ –¥–ª—è –≤—ã–±–æ—Ä–∞
    PREDEFINED_TAGS = [
        # –¢–µ—Ö–Ω–æ–ª–æ–≥–∏–∏
        "—Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏", "–∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç", "–ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏–µ", "–∫–∏–±–µ—Ä–±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å", "–¥–∞–Ω–Ω—ã–µ",
        "—Ä–æ–±–æ—Ç–æ—Ç–µ—Ö–Ω–∏–∫–∞", "–∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏—è", "–æ–±–ª–∞—á–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è", "big data", "–º–∞—à–∏–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ",
        
        # –ë–∏–∑–Ω–µ—Å
        "–±–∏–∑–Ω–µ—Å", "—Å—Ç–∞—Ä—Ç–∞–ø—ã", "–∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–∏", "–º–∞—Ä–∫–µ—Ç–∏–Ω–≥", "—Ñ–∏–Ω–∞–Ω—Å—ã", "—ç–∫–æ–Ω–æ–º–∏–∫–∞",
        "–ø—Ä–µ–¥–ø—Ä–∏–Ω–∏–º–∞—Ç–µ–ª—å—Å—Ç–≤–æ", "—É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ", "—Å—Ç—Ä–∞—Ç–µ–≥–∏—è", "–∫–æ–Ω–∫—É—Ä–µ–Ω—Ü–∏—è", "—Ä—ã–Ω–æ–∫",
        
        # –û–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ
        "–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ", "–æ–±—É—á–µ–Ω–∏–µ", "–∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–Ω–∞—É–∫–∞", "—É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç",
        "–∫—É—Ä—Å—ã", "–Ω–∞–≤—ã–∫–∏", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "–∑–Ω–∞–Ω–∏—è", "–∞–∫–∞–¥–µ–º–∏—è",
        
        # –†–∞–∑–Ω–æ–µ
        "–Ω–æ–≤–æ—Å—Ç–∏", "–∞–Ω–∞–ª–∏—Ç–∏–∫–∞", "—Ç—Ä–µ–Ω–¥—ã", "–∏–Ω–Ω–æ–≤–∞—Ü–∏–∏", "—Ä–∞–∑–≤–∏—Ç–∏–µ", "–±—É–¥—É—â–µ–µ",
        "–∑–¥–æ—Ä–æ–≤—å–µ", "—ç–∫–æ–ª–æ–≥–∏—è", "–ø–æ–ª–∏—Ç–∏–∫–∞", "–∫—É–ª—å—Ç—É—Ä–∞", "—Å–ø–æ—Ä—Ç", "–ø—É—Ç–µ—à–µ—Å—Ç–≤–∏—è",
        "–º–µ–¥–∏—Ü–∏–Ω–∞", "—Ä–∞–±–æ—Ç–∞", "–∫–∞—Ä—å–µ—Ä–∞", "–ª–∏–¥–µ—Ä—Å—Ç–≤–æ", "–∫–æ–º–∞–Ω–¥–∞", "–ø—Ä–æ–¥—É–∫—Ç–∏–≤–Ω–æ—Å—Ç—å",
        "—Å–æ—Ü–∏–∞–ª—å–Ω—ã–µ —Å–µ—Ç–∏", "–º–µ–¥–∏–∞", "–∏—Å–∫—É—Å—Å—Ç–≤–æ", "–º—É–∑—ã–∫–∞", "–∫–∏–Ω–æ", "–ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞"
    ]
    
    def __init__(self, db_path: str = "telegram_data.db", api_key: Optional[str] = None):
        """
        Args:
            db_path: –ø—É—Ç—å –∫ SQLite –±–∞–∑–µ
            api_key: API –∫–ª—é—á –¥–ª—è Groq
        """
        self.db_path = db_path
        self.api_key = api_key
        self.api_url = "https://api.groq.com/openai/v1/chat/completions"
        self.model = "llama-3.3-70b-versatile"
        
        if db_path and os.path.exists(db_path):
            self._init_db()
        
    def _init_db(self):
        """–∫–æ–Ω–Ω–µ–∫—Ç —Å –±–¥ –∏ —Å–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤—ã—Ö –∫–æ–ª–æ–Ω–æ–∫"""
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã chunks
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='chunks'
            """)
            
            if cursor.fetchone():
                columns_to_add = [
                    ("llm_tags", "TEXT"),
                    ("sentiment", "TEXT"),
                    ("explanation", "TEXT"),  # –í–º–µ—Å—Ç–æ sentiment_score
                ]
                
                for col_name, col_type in columns_to_add:
                    try:
                        cursor.execute(f"""
                            ALTER TABLE chunks ADD COLUMN {col_name} {col_type}
                        """)
                    except sqlite3.OperationalError:
                        pass
                
                conn.commit()
    
    def get_chunks(self, limit: Optional[int] = None) -> List[ChunkData]:
        """–ø–æ–ª—É—á–∞–µ–º –∏–∑ –±–¥ —á–∞–Ω–∫–∏"""
        if not os.path.exists(self.db_path):
            return []
            
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ç–∞–±–ª–∏—Ü—ã
            cursor.execute("""
                SELECT name FROM sqlite_master 
                WHERE type='table' AND name='chunks'
            """)
            
            if not cursor.fetchone():
                return []
            
            query = "SELECT id, text, metadata FROM chunks WHERE llm_tags IS NULL"
            if limit:
                query += f" LIMIT {limit}"
            
            cursor.execute(query)
            rows = cursor.fetchall()
            
            chunks = []
            for row in rows:
                chunk_id, text, metadata_str = row
                
                try:
                    existing_metadata = json.loads(metadata_str) if metadata_str else {}
                except:
                    existing_metadata = {}
                
                chunks.append(ChunkData(
                    chunk_id=chunk_id,
                    text=text,
                    existing_metadata=existing_metadata
                ))
            return chunks
    
    def analyze_with_llm(self, text: str) -> Tuple[List[str], str, str]:
        """
        –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Ç–µ–≥–∏ (–≤—ã–±–∏—Ä–∞–µ—Ç –∏–∑ –∑–∞–¥–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞) –∏ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ
        —Å –∫—Ä–∞—Ç–∫–∏–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ–º –≤—ã–±–æ—Ä–∞ —Ç–µ–≥–æ–≤
        
        –≤—ã–≤–æ–¥:
            ([—Ç–µ–≥–∏], –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ, –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ)
        """
        if not self.api_key or self.api_key == "–≤–∞—à_–∫–ª—é—á_–∑–¥–µ—Å—å":
            print("–û—à–∏–±–∫–∞: API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω")
            return [], 'neutral', 'API –∫–ª—é—á –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω'
        
        if not text or len(text.strip()) < 10:
            print("–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return [], 'neutral', '–¢–µ–∫—Å—Ç —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π'
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫—É —Å –¥–æ—Å—Ç—É–ø–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
        tags_list_str = "\n".join([f"- {tag}" for tag in self.PREDEFINED_TAGS])
        
        prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –∏ –≤—ã–ø–æ–ª–Ω–∏ —Ç—Ä–∏ –∑–∞–¥–∞–Ω–∏—è:

1. –¢–ï–ì–ò: –í—ã–±–µ—Ä–∏ —Ä–æ–≤–Ω–æ 3-5 —Å–∞–º—ã—Ö –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Ç–µ–≥–æ–≤ –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.
   - –í—ã–±–∏—Ä–∞–π —Ç–µ–≥–∏, –∫–æ—Ç–æ—Ä—ã–µ –ª—É—á—à–µ –≤—Å–µ–≥–æ –æ–ø–∏—Å—ã–≤–∞—é—Ç —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
   - –¢–æ–ª—å–∫–æ —Ç–µ–≥–∏ –∏–∑ —Å–ø–∏—Å–∫–∞ –Ω–∏–∂–µ, –Ω–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–æ–≤—ã–µ
   - –¢–µ–≥–∏ –¥–æ–ª–∂–Ω—ã –±—ã—Ç—å —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–Ω—ã–º–∏ –∏ –æ—Ö–≤–∞—Ç—ã–≤–∞—Ç—å —Ä–∞–∑–Ω—ã–µ –∞—Å–ø–µ–∫—Ç—ã —Ç–µ–∫—Å—Ç–∞

2. –ù–ê–°–¢–†–û–ï–ù–ò–ï: –û–ø—Ä–µ–¥–µ–ª–∏ –∫–∞–∫ –º–æ–∂–Ω–æ –æ—Ö–∞—Ä–∫—Ç–µ—Ä–∏–∑–æ–≤–∞—Ç—å —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç –¥–ª—è –∫–æ–º–ø–∞–Ω–∏–∏ –°–±–µ—Ä–ë–∞–Ω–∫
   - positive (–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π, –æ–ø—Ç–∏–º–∏—Å—Ç–∏—á–Ω—ã–π)
   - neutral (–Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–π, —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–π) 
   - negative (–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π, –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π)

3. –û–ë–™–Ø–°–ù–ï–ù–ò–ï: –ö—Ä–∞—Ç–∫–æ –æ–±—ä—è—Å–Ω–∏ –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω—ã –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ —Ç–µ–≥–∏ (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
   - –û–±—ä—è—Å–Ω–∏ —Å–≤—è–∑—å –º–µ–∂–¥—É —Ç–µ–∫—Å—Ç–æ–º –∏ –≤—ã–±—Ä–∞–Ω–Ω—ã–º–∏ —Ç–µ–≥–∞–º–∏
   - –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫—Ä–∞—Ç–∫–æ, –ø–æ –¥–µ–ª—É

–î–æ—Å—Ç—É–ø–Ω—ã–µ —Ç–µ–≥–∏:
{tags_list_str}

–¢–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞:
{text[:1500]}

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ (—Å—Ç—Ä–æ–≥–æ —Å–æ–±–ª—é–¥–∞–π, —ç—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω–æ!):
–¢–ï–ì–ò: —Ç–µ–≥1, —Ç–µ–≥2, —Ç–µ–≥3, —Ç–µ–≥4, —Ç–µ–≥5
–ù–ê–°–¢–†–û–ï–ù–ò–ï: positive|neutral|negative
–û–ë–™–Ø–°–ù–ï–ù–ò–ï: –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—á–µ–º—É –≤—ã–±—Ä–∞–Ω—ã –∏–º–µ–Ω–Ω–æ —ç—Ç–∏ —Ç–µ–≥–∏

–ü—Ä–∏–º–µ—Ä:
–¢–ï–ì–ò: —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–∏, –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω—ã–π –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç, –∏–Ω–Ω–æ–≤–∞—Ü–∏–∏
–ù–ê–°–¢–†–û–ï–ù–ò–ï: positive
–û–ë–™–Ø–°–ù–ï–ù–ò–ï: –í —Ç–µ–∫—Å—Ç–µ –æ–±—Å—É–∂–¥–∞—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–Ω–∏–µ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –ò–ò –∏ –∏—Ö –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö –æ—Ç—Ä–∞—Å–ª—è—Ö, —á—Ç–æ –Ω–∞–ø—Ä—è–º—É—é —Å–≤—è–∑–∞–Ω–æ —Å —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è–º–∏ –∏ –∏–Ω–Ω–æ–≤–∞—Ü–∏—è–º–∏."""

        try:
            response = requests.post(
                self.api_url,
                headers={
                    "Content-Type": "application/json",
                    "Authorization": f"Bearer {self.api_key}"
                },
                json={
                    "model": self.model,
                    "messages": [
                        {
                            "role": "system",
                            "content": """–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –∞–Ω–∞–ª–∏–∑—É —Ç–µ–∫—Å—Ç–æ–≤. 
                            –í–ê–ñ–ù–û: –°—Ç—Ä–æ–≥–æ —Å–ª–µ–¥—É–π —Ñ–æ—Ä–º–∞—Ç—É –æ—Ç–≤–µ—Ç–∞.
                            –í—ã–±–∏—Ä–∞–π —Ç–µ–≥–∏ –¢–û–õ–¨–ö–û –∏–∑ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞.
                            –û–±—ä—è—Å–Ω–µ–Ω–∏–µ –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å –∫—Ä–∞—Ç–∫–∏–º (1-2 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)."""
                        },
                        {
                            "role": "user",
                            "content": prompt
                        }
                    ],
                    "temperature": 0.3,
                    "max_tokens": 250,  # –£–≤–µ–ª–∏—á–∏–ª –¥–ª—è –æ–±—ä—è—Å–Ω–µ–Ω–∏—è
                    "stream": False
                },
                timeout=30
            )
            
            # –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å—Ç–∞—Ç—É—Å–∞ –æ—Ç–≤–µ—Ç–∞
            if response.status_code != 200:
                print(f" API –æ—à–∏–±–∫–∞: HTTP {response.status_code}")
                print(f"   –û—Ç–≤–µ—Ç: {response.text[:200]}")
                return [], 'neutral', f'API –æ—à–∏–±–∫–∞: {response.status_code}'
            
            # –ø–∞—Ä—Å–∏–º JSON
            result = response.json()
            
            if 'error' in result:
                print(f" API –æ—à–∏–±–∫–∞: {result['error'].get('message', 'Unknown error')}")
                return [], 'neutral', f"API –æ—à–∏–±–∫–∞: {result['error'].get('message', 'Unknown error')}"
            
            # –∏–∑–≤–ª–µ–∫–∞–µ–º –æ—Ç–≤–µ—Ç LLM
            if result.get('choices') and len(result['choices']) > 0:
                content = result['choices'][0]['message']['content'].strip()
                print(f"–û—Ç–≤–µ—Ç LLM:\n{content}\n{'-'*50}")
                
                # –ø–∞—Ä—Å–∏–º –æ—Ç–≤–µ—Ç
                tags = self._parse_tags(content)
                sentiment = self._parse_sentiment(content)
                explanation = self._parse_explanation(content)
                
                return tags, sentiment, explanation
            else:
                return [], 'neutral', '–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –æ—Ç–≤–µ—Ç –æ—Ç LLM'
                
        except requests.exceptions.Timeout:
            print("–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API")
            return [], 'neutral', '–¢–∞–π–º–∞—É—Ç –ø—Ä–∏ –∑–∞–ø—Ä–æ—Å–µ –∫ API'
        except Exception as e:
            print(f"–û—à–∏–±–∫–∞ LLM –∞–Ω–∞–ª–∏–∑–∞: {e}")
            return [], 'neutral', f'–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)[:100]}'
    
    def _parse_tags(self, content: str) -> List[str]:
        """–ø–∞—Ä—Å–∏–Ω–≥ —Ç–µ–≥–æ–≤ –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        tags_match = re.search(r'–¢–ï–ì–ò:\s*(.+?)(?:\n|$)', content, re.IGNORECASE)
        if tags_match:
            tags_text = tags_match.group(1).strip()
            tags = [tag.strip() for tag in tags_text.split(',')]
            
            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Ç–µ–≥–∏ –∏–∑ —Å–ø–∏—Å–∫–∞
            valid_tags = []
            for tag in tags:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ç–æ—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
                if tag in self.PREDEFINED_TAGS and tag not in valid_tags:
                    valid_tags.append(tag)
                else:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –±–µ–∑ —É—á–µ—Ç–∞ —Ä–µ–≥–∏—Å—Ç—Ä–∞
                    for predefined_tag in self.PREDEFINED_TAGS:
                        if predefined_tag.lower() == tag.lower() and predefined_tag not in valid_tags:
                            valid_tags.append(predefined_tag)
                            break
            
            # –ï—Å–ª–∏ —Ç–µ–≥–æ–≤ –º–∞–ª–æ, –ø—ã—Ç–∞–µ–º—Å—è –Ω–∞–π—Ç–∏ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤—ã
            if len(valid_tags) < 2 and len(tags) > 0:
                # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ —Ç–µ–≥–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
                tag_lower = tags[0].lower()
                for predefined_tag in self.PREDEFINED_TAGS:
                    if tag_lower in predefined_tag.lower() and predefined_tag not in valid_tags:
                        valid_tags.append(predefined_tag)
                        if len(valid_tags) >= 3:
                            break
            
            return valid_tags[:5]  # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –º–∞–∫—Å–∏–º—É–º 5 —Ç–µ–≥–æ–≤
        
        return []
    
    def _parse_sentiment(self, content: str) -> str:
        """–ø–∞—Ä—Å–∏–Ω–≥ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        sentiment = 'neutral'
        sentiment_match = re.search(r'–ù–ê–°–¢–†–û–ï–ù–ò–ï:\s*(positive|neutral|negative)', content, re.IGNORECASE)
        if sentiment_match:
            sentiment = sentiment_match.group(1).lower()
        
        return sentiment
    
    def _parse_explanation(self, content: str) -> str:
        """–ø–∞—Ä—Å–∏–Ω–≥ –æ–±—ä—è—Å–Ω–µ–Ω–∏—è –∏–∑ –æ—Ç–≤–µ—Ç–∞ LLM"""
        explanation = '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–æ'
        
        # –ò—â–µ–º –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –ø–æ—Å–ª–µ –º–µ—Ç–∫–∏ –û–ë–™–Ø–°–ù–ï–ù–ò–ï:
        explanation_match = re.search(r'–û–ë–™–Ø–°–ù–ï–ù–ò–ï:\s*(.+?)(?:\n\n|\n$|$)', content, re.IGNORECASE | re.DOTALL)
        if explanation_match:
            explanation = explanation_match.group(1).strip()
            # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª–∏–Ω—É
            if len(explanation) > 500:
                explanation = explanation[:497] + "..."
        else:
            # –ü–æ–ø—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –±–µ–∑ –º–µ—Ç–∫–∏
            lines = content.split('\n')
            for i, line in enumerate(lines):
                if '–¢–ï–ì–ò:' in line and i + 3 < len(lines):
                    # –í–æ–∑–º–æ–∂–Ω–æ, –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ 2-3 —Å—Ç—Ä–æ–∫–∏ –ø–æ—Å–ª–µ —Ç–µ–≥–æ–≤
                    for j in range(1, 4):
                        if i + j < len(lines):
                            potential_explanation = lines[i + j].strip()
                            if (potential_explanation and 
                                not potential_explanation.startswith('–ù–ê–°–¢–†–û–ï–ù–ò–ï:') and
                                not potential_explanation.startswith('–¢–ï–ì–ò:') and
                                not potential_explanation.startswith('–£–í–ï–†–ï–ù–ù–û–°–¢–¨:')):
                                explanation = potential_explanation
                                break
        
        return explanation
    
    def save_to_db(self, chunk_id: int, llm_tags: List[str], 
                   sentiment: str, explanation: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ –ë–î"""
        if not os.path.exists(self.db_path):
            print(f"–ë–î {self.db_path} –Ω–µ –Ω–∞–π–¥–µ–Ω–∞, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –ø—Ä–æ–ø—É—â–µ–Ω–æ")
            return
            
        with sqlite3.connect(self.db_path) as conn:
            cursor = conn.cursor()
            
            cursor.execute("""
                UPDATE chunks 
                SET llm_tags = ?, 
                    sentiment = ?,
                    explanation = ?
                WHERE id = ?
            """, (
                json.dumps(llm_tags, ensure_ascii=False),
                sentiment,
                explanation,
                chunk_id
            ))
            
            conn.commit()
    
    def process_chunk(self, chunk: ChunkData, delay: float = 0.5) -> Dict:
        """
        –æ–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ —á–∞–Ω–∫–∞
        """
        print(f"\n{'='*60}")
        print(f"üìã –û–±—Ä–∞–±–æ—Ç–∫–∞ —á–∞–Ω–∫–∞ #{chunk.chunk_id}")
        print(f"{'='*60}")
        print(f"üìù –¢–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
        print(f"   {chunk.text[:200]}...")
        
        # –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        llm_tags, sentiment, explanation = self.analyze_with_llm(chunk.text)
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   üè∑Ô∏è  –¢–µ–≥–∏: {', '.join(llm_tags) if llm_tags else '–Ω–µ –≤—ã–±—Ä–∞–Ω—ã'}")
        print(f"   üòä –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {sentiment}")
        print(f"   üìù –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {explanation}")
        
        # —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
        self.save_to_db(
            chunk.chunk_id, llm_tags, sentiment, explanation)
        
        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –≤ –ë–î")
        
        # –∑–∞–¥–µ—Ä–∂–∫–∞ –¥–ª—è rate limit
        time.sleep(delay)
        
        return {
            'chunk_id': chunk.chunk_id,
            'llm_tags': llm_tags,
            'sentiment': sentiment,
            'explanation': explanation,
        }
    
    def process_all(self, limit: Optional[int] = None, delay: float = 0.5):
        """
        –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö —á–∞–Ω–∫–æ–≤ –∏–∑ –ë–î
        """
        chunks = self.get_chunks(limit=limit)
        
        if not chunks:
            print("‚ÑπÔ∏è  –ù–µ—Ç —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            return []
        
        print(f"üîç –ù–∞–π–¥–µ–Ω–æ {len(chunks)} —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏")
        
        results = []
        for i, chunk in enumerate(chunks, 1):
            print(f"\nüîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ {i}/{len(chunks)}")
            
            try:
                result = self.process_chunk(chunk, delay=delay)
                results.append(result)
                
            except Exception as e:
                print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ chunk {chunk.chunk_id}: {e}")
                continue
        
        print(f"\n{'='*60}")
        print(f"üéâ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {len(results)} —á–∞–Ω–∫–æ–≤")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        if results:
            sentiments = [r['sentiment'] for r in results]
            from collections import Counter
            sentiment_stats = Counter(sentiments)
            
            print(f"\nüìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–π:")
            for sentiment, count in sentiment_stats.items():
                print(f"   {sentiment}: {count}")
        
        return results

    def analyze_text(self, text: str) -> Dict:
        """
        –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –ë–î
        """
        print(f"\n{'='*60}")
        print(f"üîç –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞")
        print(f"{'='*60}")
        print(f"üìù –¢–µ–∫—Å—Ç (–ø–µ—Ä–≤—ã–µ 200 —Å–∏–º–≤–æ–ª–æ–≤):")
        print(f"   {text[:200]}...")
        
        llm_tags, sentiment, explanation = self.analyze_with_llm(text)
        
        result = {
            'llm_tags': llm_tags,
            'sentiment': sentiment,
            'explanation': explanation,
        }
        
        print(f"\n‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞:")
        print(f"   üè∑Ô∏è  –¢–µ–≥–∏: {', '.join(llm_tags)}")
        print(f"   üòä –ù–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {sentiment}")
        print(f"   üìù –û–±—ä—è—Å–Ω–µ–Ω–∏–µ: {explanation}")
        
        return result


def main():
    """
    –ü—Ä–∏–º–µ—Ä –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è
    """
    # –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è
    classifier = LLMMetadataClassifier(
        db_path="telegram_data.db",
        api_key=API_KEY
    )
    
    if API_KEY is None:
        print("‚ùå –û—à–∏–±–∫–∞: GROQ_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è")
        print("üìù –°–æ–∑–¥–∞–π—Ç–µ —Ñ–∞–π–ª .env —Å —Å–æ–¥–µ—Ä–∂–∏–º—ã–º: GROQ_API_KEY=–≤–∞—à_–∫–ª—é—á")
        return
    
    # –æ–±—Ä–∞–±–æ—Ç–∫–∞
    results = classifier.process_all(
        limit=5,
        delay=0.5 
    )
    
    # –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    if results:
        print(f"\nüìã –ò—Ç–æ–≥–æ–≤—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        for result in results:
            print(f"\n–ß–∞–Ω–∫ {result['chunk_id']}:")
            print(f"  üè∑Ô∏è  {', '.join(result['llm_tags'])}")
            print(f"  üòä {result['sentiment']}")
            print(f"  üìù {result['explanation']}")


if __name__ == "__main__":
    main()